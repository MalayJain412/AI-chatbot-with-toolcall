# ğŸ§  AI Chatbot with Tool Calling (FastAPI + Azure OpenAI + LangChain)

This project is a **production-ready AI chatbot backend** built with:

âœ… **Azure OpenAI (GPT-4.1-Mini)**  
âœ… **LangChain Agents & Tools**  
âœ… **FastAPI backend**  
âœ… **Custom tools including email lookup & web search**  
âœ… **Extensible design to support MongoDB queries**

The chatbot is capable of:

* Understanding natural language queries
* Deciding whether a tool is needed
* Calling backend functions automatically
* Returning natural human-like responses

---

## ğŸš€ Features

### ğŸ¤– LLM-Powered Chatbot

Uses **Azure OpenAI GPT-4.1-Mini** as the reasoning engine.

### ğŸ›  Tool Calling

The chatbot intelligently calls backend functions such as:

* ğŸ” `web_search` â€” Searches DuckDuckGo
* ğŸ“§ `get_user_email_id` â€” Returns email IDs based on query
* (Future) ğŸ—„ MongoDB query tools

### ğŸŒ REST API

One simple endpoint:

```
POST /chat
```

### ğŸ’¬ Conversational Memory

Keeps context across messages.

### ğŸ“œ System Prompt Control

Defines chatbot policy & behavior.

---

## ğŸ— Architecture Overview

```
User â†’ FastAPI â†’ Azure OpenAI â†’ Tool Selected â†’ Backend Executes
        â†‘                                       â†“
        â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Final Answer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**LLM = Brain**  
**Tools = Muscles**  
**Backend = Orchestrator**

```mermaid
graph TD
    A[User] --> B[FastAPI]
    B --> C[Azure OpenAI]
    C --> D{Decision Point}
    D -->|Tool Needed| E[Tool Selection]
    E --> F[Tool Execution]
    F --> G[Result Processing]
    G --> H[LLM Response]
    H --> I[Final Answer]
    D -->|No Tool| J[Direct Response]
    J --> I
    I --> A
```

---

## ğŸ“‚ Project Structure

```
AI-chatbot-with-toolcall/
â”œâ”€â”€ main.py              # FastAPI app + Agent logic
â”œâ”€â”€ tools.py             # Tool functions
â”œâ”€â”€ config.py            # Azure credentials
â”œâ”€â”€ malay.txt            # Profile data file
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ send_email.py        # Email sending helper
â”œâ”€â”€ templates.py         # Template selection / utilities
â”œâ”€â”€ email_templates/     # HTML email templates
â”‚   â”œâ”€â”€ admin_templete.html
â”‚   â””â”€â”€ user_templete.html
â”œâ”€â”€ frontend/            # Simple web UI for the chatbot
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ README.md
â””â”€â”€ README.md            # Backend & project docs
```

```mermaid
graph TD
    A[AI-chatbot-with-toolcall] --> B[main.py<br/>FastAPI + Agent]
    A --> C[tools.py<br/>Tool Functions]
    A --> D[config.py<br/>Azure Config]
    A --> E[malay.txt<br/>Data File]
    A --> F[requirements.txt<br/>Deps]
    A --> G[send_email.py<br/>Email Helper]
    A --> H[templates.py<br/>Template Utils]
    A --> I[email_templates/<br/>HTML Email Templates]
    A --> J[frontend/<br/>Web UI]
    A --> K[README.md<br/>Docs]
```

---

## ğŸŒ Frontend UI

The web UI for this chatbot is developed in a separate repository and mirrored here for convenience:

* GitHub repo: https://github.com/MalayJain412/Frontend-UI-for-AI-Chatbot-fastapi
* Local folder in this project: `frontend/`
* Entry file: `frontend/index.html`
* Frontend docs: `frontend/README.md`

To try it out, start the FastAPI backend, then either open `frontend/index.html` directly in your browser or serve the `frontend/` directory with a static server (for example, VS Code Live Server or `python -m http.server`). Make sure any API base URL used in the frontend points to your running backend (for example, `http://127.0.0.1:8000/chat`).

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone repo & create venv

```bash
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
```

---

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

### 3ï¸âƒ£ Configure Azure OpenAI

Create a `.env` file in the root directory of the project:

```env
AZURE_OPENAI_ENDPOINT=https://YOUR-RESOURCE.openai.azure.com/
AZURE_OPENAI_API_KEY=YOUR_KEY
AZURE_DEPLOYMENT=gpt-4.1-mini
AZURE_API_VERSION=2025-01-01-preview
```

> **Note:** The `config.py` file automatically loads these environment variables using `python-dotenv`. Deployment name must match your Azure Studio deployment.

---

### 4ï¸âƒ£ Run server

```bash
uvicorn main:app --reload
```

Server runs at:

```
http://127.0.0.1:8000
```

---

## ğŸ§° Tools Explained

### ğŸ” 1. Web Search Tool

Searches online using DuckDuckGo API.

Used for **general knowledge queries**.

---

### ğŸ“§ 2. Email Lookup Tool

Example:

```python
get_user_email_id("What is Malay's email?")
```

Returns:

```
malayjain1234@gmail.com
```

Logic:

| Name       | Email                                                     |
| ---------- | --------------------------------------------------------- |
| Malay Jain | [malayjain1234@gmail.com](mailto:malayjain1234@gmail.com) |
| Aniket     | [anni990@gmail.com](mailto:anni990@gmail.com)             |

Tool docstring tells the LLM **when** to use it.

---

## ğŸ§  How Tool Calling Works (Simple Explanation)

1ï¸âƒ£ User asks a question  
2ï¸âƒ£ LLM decides whether a tool is needed  
3ï¸âƒ£ If yes â†’ passes arguments to tool  
4ï¸âƒ£ Backend executes Python function  
5ï¸âƒ£ Result is returned to LLM  
6ï¸âƒ£ LLM writes natural reply

Example:

```
User: What is Malay's email?
LLM â†’ ToolCall(get_user_email_id)
Backend returns email
LLM responds naturally
```

Magic âœ¨

```mermaid
sequenceDiagram
    participant U as User
    participant L as LLM
    participant T as Tool
    participant B as Backend

    U->>L: Asks question
    L->>L: Evaluates need for tool
    L->>T: Calls tool with arguments
    T->>B: Executes function
    B->>T: Returns result
    T->>L: Provides result
    L->>U: Generates natural response
```

---

## ğŸ§© System Prompt Role

Controls:

âœ” assistant behavior  
âœ” tone  
âœ” policy  
âœ” general rules

Example rules:

* Prefer local tools for internal data
* Use web search only when required
* Do not mention tool names

---

## ğŸ”Š Verbose Logging

`verbose=True`

Shows:

* tool selection
* reasoning chain
* inputs & outputs

Useful for debugging.

---

## ğŸ›¡ Security Notes

âœ” API keys are never exposed  
âœ” Tools run in backend only  
âœ” Email lookup prevents hallucination  
âœ” Invalid requests return safe output

---

## ğŸ§ª Testing the Chat API

Send request:

```
POST /chat
Content-Type: application/json
```

Body:

```json
{
  "message": "What is Malay's email?"
}
```

---

## ğŸ› Tech Stack

| Component | Technology       |
| --------- | ---------------- |
| Backend   | FastAPI          |
| LLM       | Azure OpenAI     |
| Agent     | LangChain        |
| Tools     | Python functions |
| Memory    | LangChain buffer |

---

## ğŸ“Œ Why LangChain?

LangChain handles:

âœ” conversation history  
âœ” tool routing  
âœ” argument passing  
âœ” agent reasoning  
âœ” debug logging

So you write less glue code.

---

## ğŸ§  Future Enhancements

ğŸ“Œ Add MongoDB query tools  
ğŸ“Œ Structured tool calling  
ğŸ“Œ Auth & rate limiting  
ğŸ“Œ Frontend UI  
ğŸ“Œ Docker image

---

## ğŸ Summary

This project demonstrates a **realistic production-grade AI chatbot backend** that combines:

ğŸ§  Azure OpenAI reasoning  
ğŸ›  Python business logic  
ğŸš€ FastAPI deployment  
ğŸ§© LangChain agents

It's clean, extensible, and powerful.

---

## ğŸ¤ Contributing

PRs & suggestions welcome ğŸ‘

---

## ğŸ“„ License

MIT